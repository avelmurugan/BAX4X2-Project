{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "import codecs\n",
    "import os\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from pymongo import MongoClient\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "import http.client, urllib.parse\n",
    "from pymongo import MongoClient\n",
    "from urllib.parse import quote_plus\n",
    "from dataprep.datasets import load_dataset\n",
    "from dataprep.eda import create_report\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from fancyimpute import KNN\n",
    "from statistics import mode\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBClassifier, plot_tree\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "#Connecting to mongoDB\n",
    "mo_c = MongoClient()\n",
    "client = MongoClient('localhost', 27017)\n",
    "#access database\n",
    "db = client[\"craigslist_cars\"]\n",
    "collection_sf=db[\"bay_area\"]\n",
    "collection_sd=db['sd']\n",
    "collection_la=db['los_angeles']\n",
    "\n",
    "bay_area_df = pd.DataFrame(list(collection_sf.find({})))\n",
    "san_diego_df = pd.DataFrame(list(collection_sd.find({})))\n",
    "los_angeles_df = pd.DataFrame(list(collection_la.find({})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat 3 dfs to create a full df\n",
    "full_df = pd.DataFrame()\n",
    "full_df = pd.concat([bay_area_df, san_diego_df, los_angeles_df])\n",
    "\n",
    "full_df.drop('posted_stats', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>url</th>\n",
       "      <th>full_car_brand</th>\n",
       "      <th>year</th>\n",
       "      <th>brand</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odo</th>\n",
       "      <th>cond</th>\n",
       "      <th>paint</th>\n",
       "      <th>cyl</th>\n",
       "      <th>title</th>\n",
       "      <th>trans</th>\n",
       "      <th>drive</th>\n",
       "      <th>body_type</th>\n",
       "      <th>img_url</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>641404f459aa7868e84596fd</td>\n",
       "      <td>https://sfbay.craigslist.org/sfc/cto/d/san-fra...</td>\n",
       "      <td>Honda Element 2008 EX</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>honda</td>\n",
       "      <td>gas</td>\n",
       "      <td>156900.0</td>\n",
       "      <td>excellent</td>\n",
       "      <td>grey</td>\n",
       "      <td>4.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>manual</td>\n",
       "      <td>fwd</td>\n",
       "      <td>SUV</td>\n",
       "      <td>https://images.craigslist.org/00707_6t1Lg18wmo...</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>641404f459aa7868e84596fe</td>\n",
       "      <td>https://sfbay.craigslist.org/eby/cto/d/martine...</td>\n",
       "      <td>2009 kia spectra</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>kia</td>\n",
       "      <td>gas</td>\n",
       "      <td>152000.0</td>\n",
       "      <td>good</td>\n",
       "      <td>red</td>\n",
       "      <td>4.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>fwd</td>\n",
       "      <td>sedan</td>\n",
       "      <td>https://images.craigslist.org/00b0b_jKLhf1Pv6U...</td>\n",
       "      <td>3850.0</td>\n",
       "      <td>mid-size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>641404f459aa7868e84596ff</td>\n",
       "      <td>https://sfbay.craigslist.org/eby/cto/d/oakland...</td>\n",
       "      <td>2012 Subaru Impreza</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>subaru</td>\n",
       "      <td>gas</td>\n",
       "      <td>133000.0</td>\n",
       "      <td>good</td>\n",
       "      <td>white</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>https://images.craigslist.org/00d0d_c8TotKANf7...</td>\n",
       "      <td>9800.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>641404f459aa7868e8459700</td>\n",
       "      <td>https://sfbay.craigslist.org/sby/cto/d/san-jos...</td>\n",
       "      <td>2016 smart car prime low mile</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gas</td>\n",
       "      <td>33000.0</td>\n",
       "      <td>like new</td>\n",
       "      <td>blue</td>\n",
       "      <td>3.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>rwd</td>\n",
       "      <td>other</td>\n",
       "      <td>https://images.craigslist.org/00000_g6c68odvnk...</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>641404f459aa7868e8459701</td>\n",
       "      <td>https://sfbay.craigslist.org/eby/cto/d/hayward...</td>\n",
       "      <td>2015 FORD TRANSIT CONNECT XLT CARGO VAN</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>gas</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://images.craigslist.org/00101_jaSFzUnrP7...</td>\n",
       "      <td>14200.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  641404f459aa7868e84596fd   \n",
       "1  641404f459aa7868e84596fe   \n",
       "2  641404f459aa7868e84596ff   \n",
       "3  641404f459aa7868e8459700   \n",
       "4  641404f459aa7868e8459701   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://sfbay.craigslist.org/sfc/cto/d/san-fra...   \n",
       "1  https://sfbay.craigslist.org/eby/cto/d/martine...   \n",
       "2  https://sfbay.craigslist.org/eby/cto/d/oakland...   \n",
       "3  https://sfbay.craigslist.org/sby/cto/d/san-jos...   \n",
       "4  https://sfbay.craigslist.org/eby/cto/d/hayward...   \n",
       "\n",
       "                            full_car_brand    year   brand fuel       odo  \\\n",
       "0                    Honda Element 2008 EX  2008.0   honda  gas  156900.0   \n",
       "1                         2009 kia spectra  2009.0     kia  gas  152000.0   \n",
       "2                      2012 Subaru Impreza  2012.0  subaru  gas  133000.0   \n",
       "3            2016 smart car prime low mile  2016.0     NaN  gas   33000.0   \n",
       "4  2015 FORD TRANSIT CONNECT XLT CARGO VAN  2015.0    ford  gas  150000.0   \n",
       "\n",
       "        cond  paint  cyl  title      trans drive  body_type  \\\n",
       "0  excellent   grey  4.0  clean     manual   fwd        SUV   \n",
       "1       good    red  4.0  clean  automatic   fwd      sedan   \n",
       "2       good  white  NaN  clean  automatic   4wd  hatchback   \n",
       "3   like new   blue  3.0  clean  automatic   rwd      other   \n",
       "4        NaN    NaN  NaN  clean  automatic   NaN        NaN   \n",
       "\n",
       "                                             img_url    price      size  \n",
       "0  https://images.craigslist.org/00707_6t1Lg18wmo...   4500.0       NaN  \n",
       "1  https://images.craigslist.org/00b0b_jKLhf1Pv6U...   3850.0  mid-size  \n",
       "2  https://images.craigslist.org/00d0d_c8TotKANf7...   9800.0       NaN  \n",
       "3  https://images.craigslist.org/00000_g6c68odvnk...  11000.0   compact  \n",
       "4  https://images.craigslist.org/00101_jaSFzUnrP7...  14200.0       NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv('price_prediction_df.csv')\n",
    "#optional:read in file from csv:\n",
    "#full_df=pd.read_csv('price_prediction_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CLEANING\n",
    "full_df = full_df.dropna(subset=['full_car_brand','fuel','odo','title','trans','img_url']) \n",
    "df1 = full_df.loc[:, ['year', 'odo', 'cyl', 'price']]\n",
    "df2 = full_df.drop(['year', 'odo', 'cyl', 'price'], axis=1)\n",
    "\n",
    "##NUMERIC KNN IMPUTING\n",
    "df1 = df1.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#Need to hyperparametrize n here\n",
    "# apply KNNImputer to the dataframe\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "df1_imputed = pd.DataFrame(imputer.fit_transform(df1), columns=df1.columns)\n",
    "\n",
    "# print the resulting dataframe\n",
    "print(df1_imputed)\n",
    "\n",
    "df = df2.join(df1_imputed)\n",
    "df = df.drop(['size','drive','paint'],axis=1)\n",
    "\n",
    "##REMOVING ALL NULL ROWS\n",
    "bad_index = df[df['brand'].isnull()].index\n",
    "df.drop(bad_index, inplace = True)\n",
    "\n",
    "bad_index = df[df['odo'].isnull()].index\n",
    "df.drop(bad_index, inplace = True)\n",
    "\n",
    "bad_index = df[df['cyl'].isnull()].index\n",
    "df.drop(bad_index, inplace = True)\n",
    "\n",
    "bad_index = df[df['price'].isnull()].index\n",
    "df.drop(bad_index, inplace = True)\n",
    "\n",
    "df.isna().sum()\n",
    "\n",
    "\n",
    "df['body_type'] = df['body_type'].fillna(value=df['body_type'].mode()[0])\n",
    "df['cond'] = df['cond'].fillna(value=df['cond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FEATURE ANALYSIS\n",
    "\n",
    "##REMOVING OUTLIERS FROM YEAR\n",
    "\n",
    "# Outlier detection \n",
    "\n",
    "def detect_outliers(df,n,features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the Tukey method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    \n",
    "    return multiple_outliers   \n",
    "\n",
    "# detect outliers from Price, year & odo\n",
    "Outliers_to_drop = detect_outliers(df,0,[\"price\",\"year\",\"odo\"])\n",
    "\n",
    "df.loc[Outliers_to_drop] # Show the outliers rows\n",
    "df = df.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ONE-HOT ENCODING\n",
    "df = pd.get_dummies(df, columns=['brand','fuel','cond','title','trans','body_type'])\n",
    "df.head()\n",
    "\n",
    "data_train, data_test = train_test_split(df, test_size = 0.3, random_state = 12)\n",
    "\n",
    "y = df.loc[:,['price']]\n",
    "x = df.drop(['price'],axis=1)\n",
    "x = x.drop(['_id','url','full_car_brand','img_url'],axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##XGBOOST\n",
    "\n",
    "n_iter_search = 50\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [500, 1000, 2500],\n",
    "    'eta': [0.1, 0.25, 0.75, 1],\n",
    "    'reg_alpha':[0.75, 0.5, 0.3 ,0.2, 0.1, 1], \n",
    "    'booster': ['gbtree'],\n",
    "    'reg_lambda': [1e-5, 1e-2, 0.1, 1],\n",
    "    'scale_pos_weight':[ 5, 10, 25],\n",
    "}\n",
    "\n",
    "\n",
    "model = XGBRegressor()\n",
    "grid_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter = n_iter_search, cv=5, scoring ='neg_mean_squared_error')\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################LASSO REGRESSION################################################################\n",
    "param_grid2 = {'alpha': (np.logspace(-5, 5, 100))} \n",
    "\n",
    "model2 = Lasso(normalize=True)\n",
    "grid_search2 = RandomizedSearchCV(estimator=model, param_distributions=param_grid2, n_iter=n_iter_search, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search2.fit(x_train, y_train)\n",
    "best_params2 = grid_search2.best_params_\n",
    "best_model2 = grid_search2.best_estimator_\n",
    "y_pred2 = best_model2.predict(x_test)\n",
    "mse2 = mean_squared_error(y_test, y_pred2)\n",
    "mse2**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################RIDGE REGRESSION###################################################################\n",
    "\n",
    "model3 = Ridge(normalize=True)\n",
    "grid_search3 = RandomizedSearchCV(estimator=model, param_distributions=param_grid2, n_iter=n_iter_search, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search3.fit(x_train, y_train)\n",
    "best_params3 = grid_search3.best_params_\n",
    "best_model3 = grid_search3.best_estimator_\n",
    "y_pred3 = best_model3.predict(x_test)\n",
    "mse3 = mean_squared_error(y_test, y_pred3)\n",
    "mse3**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########RANDOM FOREST##############################################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train, y_train)\n",
    "\n",
    "#Evaluating the model\n",
    "\n",
    "best_params_rf = rf_random.best_params_\n",
    "best_model_rf = rf_random.best_estimator_\n",
    "y_pred_rf = best_model_rf.predict(x_test)\n",
    "mse4 = mean_squared_error(y_test, y_pred_rf)\n",
    "print(mse4)\n",
    "r2 = r2_score(y_test, y_pred2)\n",
    "print(r2)\n",
    "\n",
    "rmse = np.sqrt(mse4)\n",
    "print(rmse)\n",
    "\n",
    "print(best_params_rf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
